ğŸ” Privacyâ€‘Preserving LLM Pipeline
Secure Prompt â†’ PII Masking â†’ LLM â†’ Unmasking â†’ Response
Built with Presidio, custom recognizers, Google Gemini, and a Streamlit UI

This project implements a fully privacyâ€‘preserving LLM orchestration pipeline. It ensures that no raw PII ever reaches the LLM, thanks to a masking layer powered by Microsoft Presidio and custom dictionary recognizers.
A Streamlit UI provides a transparent, interactive chat experience with visibility into every stage of the pipeline.

ğŸ“ Project Structure
Code
.
â”œâ”€â”€ agents/                 # Orchestration logic (mask â†’ LLM â†’ unmask)
â”œâ”€â”€ config/                 # YAML config (API keys, model, PII toggles)
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ recognizers/            # Custom Presidio recognizers
â”œâ”€â”€ ui/                     # Streamlit UI components
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ sample_prompts.json
This structure cleanly separates concerns:

agents handles the pipeline logic

config centralizes runtime settings

recognizers extends PII detection

ui provides the interactive interface

âš™ï¸ Configuration (config/config.yaml)
Your configuration file controls the entire system â€” model selection, API keys, and which PII categories are masked.

yaml
GEMINI_API_KEY: "YOUR_KEY_HERE123"
MODEL_NAME: "gemini-1.5-pro"

# Toggle LLM usage (useful for debugging without burning tokens)
USE_LLM: false

# Enable/disable PII categories for masking
PII_CATEGORIES_ENABLED:
  PERSON: true
  EMAIL_ADDRESS: true
  PHONE_NUMBER: true
  CREDIT_CARD: true
  IP_ADDRESS: true
  LOCATION: true
  CLIENT_ID: true
  ACCOUNT_REFERENCE: true
  ORGANIZATION: true
  DATE_TIME: false
  DOMAIN_NAME: false
Why this config works well
Centralized, humanâ€‘readable settings

Easy to extend with new PII categories

Supports turning the LLM off for local debugging

Safe to commit (as long as API keys are injected via env vars in production)

ğŸš€ Features
ğŸ”’ Privacyâ€‘Preserving LLM Flow
Presidioâ€‘based PII detection

Custom dictionary recognizers for domainâ€‘specific entities

Automatic masking before sending text to Gemini

LLM inference on masked text only

Deterministic unmasking of the final response

ğŸ–¥ï¸ Streamlit UI
Chat interface with history

Masked vs. unmasked prompt views

LLM response view

Final unmasked output

Toggle switches for PII categories (mirroring config.yaml)

ğŸ§± Architecture Overview
Code
User Prompt
    â†“
Presidio Analyzer (builtâ€‘in + custom recognizers)
    â†“
Masking Layer (tokenized placeholders)
    â†“
Google Gemini LLM (masked text only)
    â†“
Unmasking Layer (restores original PII)
    â†“
Final Response
This ensures compliant, privacyâ€‘preserving AI interactions.

ğŸ“¦ Installation
1. Clone the repository
bash
git clone <your-repo-url>
cd <your-project-folder>
2. Create a virtual environment
bash
python3 -m venv venv
source venv/bin/activate   # macOS/Linux
venv\Scripts\activate      # Windows
3. Install dependencies
bash
pip install -r requirements.txt
4. Configure environment variables
Create a .env file:

Code
GEMINI_API_KEY=your_key_here
The YAML config will read this automatically if your loader supports env overrides.

â–¶ï¸ Running the App
bash
streamlit run ui/app.py
The UI will open at:

Code
http://localhost:8501
ğŸ§© Custom Recognizers
Place your custom Presidio recognizers in:

Code
recognizers/
These may include:

Dictionaryâ€‘based recognizers

Regexâ€‘based recognizers

Domainâ€‘specific entity detectors

They are automatically loaded into the analyzer at startup.

ğŸ” Example Workflow
Input:

â€œEmail John Doe at john.doe@company.com about the contract.â€

Masked:

â€œEmail PERSON_1 at EMAIL_1 about the contract.â€

LLM Output (masked):

â€œSure, Iâ€™ll draft an email to PERSON_1.â€

Final Unmasked Output:

â€œSure, Iâ€™ll draft an email to John Doe.â€

ğŸ§ª Testing
Run tests with:

bash
pytest
Tests cover:

PII detection

Masking/unmasking consistency

Recognizer accuracy

LLM pipeline integration

ğŸ—ºï¸ Roadmap
Add support for multiple LLM providers

Add audit logging for compliance

Add batch document processing

Add UIâ€‘based config editing

ğŸ¤ Contributing
Contributions are welcome.
If you add new recognizers or pipeline components, please include tests and documentation.

ğŸ“œ License
MIT License (or your preferred license)
